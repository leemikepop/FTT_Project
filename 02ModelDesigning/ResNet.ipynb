{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob,pandas,time,os\n",
    "\n",
    "import torch,torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsummary import summary\n",
    "from torcheval.metrics.functional import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "True\n",
      "11.7\n",
      "8500\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device.type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self,file_paths,labels_lists,transform):\n",
    "        super().__init__()\n",
    "        self.file_paths = file_paths\n",
    "        self.labels_lists = labels_lists\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        image = Image.open(self.file_paths[index])\n",
    "        image = self.transform(image).float()\n",
    "        labels = self.labels_lists[index]\n",
    "        labels = np.array(labels)\n",
    "        labels = labels.astype('float').reshape(-1,4)\n",
    "        sample = {'image':image,'psi':labels}\n",
    "        return sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDataLoader(images_fp,labels_fp,config,RGB_mean=(0.485, 0.456, 0.406),RGB_std=(0.229, 0.224, 0.225)):\n",
    "    df = pandas.read_csv(labels_fp)\n",
    "    df = df.iloc[:,20:24]\n",
    "    psi = df.to_numpy()\n",
    "    img_pl = glob.glob(images_fp)\n",
    "    img_pl = np.array(img_pl)\n",
    "\n",
    "    #shuffle\n",
    "    orig_dataset = np.c_[img_pl,psi]\n",
    "    np.random.seed(config['random_seed'])\n",
    "    np.random.shuffle(orig_dataset)\n",
    "\n",
    "    #split into train and test\n",
    "    train_inputs, validation_inputs, test_inputs = [],[],[]\n",
    "    train_labels, validation_labels, test_labels = [],[],[]\n",
    "    train_num = int(len(orig_dataset)*0.6)\n",
    "    val_num = int(len(orig_dataset)*0.8)\n",
    "    for data in orig_dataset[:train_num]:\n",
    "        train_inputs.append(data[0])\n",
    "        train_labels.append([data[1:]])\n",
    "    for data in orig_dataset[train_num:val_num]:\n",
    "        validation_inputs.append(data[0])\n",
    "        validation_labels.append([data[1:]])\n",
    "    for data in orig_dataset[val_num:]:\n",
    "        test_inputs.append(data[0])\n",
    "        test_labels.append([data[1:]])\n",
    "\n",
    "    input_size = config['input_size'][1]\n",
    "    # normalize = torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    normalize = torchvision.transforms.Normalize(mean = RGB_mean.tolist(), std = RGB_std.tolist())\n",
    "    data_transforms = {\n",
    "        'train': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(input_size),\n",
    "            # torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]),\n",
    "        'val': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(input_size),\n",
    "            # torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]),\n",
    "        'test': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(input_size),\n",
    "            # torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    train_dataLoader = DataLoader(MyDataSet(train_inputs,train_labels,data_transforms['train']),batch_size=config['batch_size'],shuffle=True)\n",
    "    validation_dataLoader = DataLoader(MyDataSet(train_inputs,train_labels,data_transforms['val']),batch_size=config['batch_size'],shuffle=True)\n",
    "    test_dataLoader = DataLoader(MyDataSet(test_inputs,test_labels,data_transforms['test']),batch_size=1,shuffle=False)\n",
    "    \n",
    "    return train_dataLoader,validation_dataLoader,test_dataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_update(model:nn.Module)->list:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            # print(\"\\t\",name)\n",
    "    return params_to_update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def validation(validation_dataLoader:DataLoader,model:torch.nn.Module,criterion,device:torch.device):\n",
    "    model.eval()\n",
    "    loss = []\n",
    "    for _, sample in enumerate(validation_dataLoader) :\n",
    "        x, y = sample['image'].to(device), sample['psi'].to(device).float().squeeze(dim=1)\n",
    "        with torch.no_grad():\n",
    "            predict = model(x)\n",
    "            loss.append(criterion(predict,y).detach().cpu().item())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "def train(train_dataLoader:DataLoader,validation_dataLoader:DataLoader,model:torch.nn.Module,config,device:torch.device):\n",
    "    max_epochs = config['max_epochs']\n",
    "    params_to_update_list = params_to_update(model)\n",
    "    optimizer = getattr(torch.optim,config['optimizer'])(params_to_update_list,**config['optim_hparas'])   # Setup optimizer\n",
    "    criterion = getattr(torch.nn,config['lossFunc'])(**config['loss_hparas'])                           # Setup criterion\n",
    "\n",
    "    min_loss = 1000.\n",
    "    loss_record = {'train':[],'validation':[]}\n",
    "    early_stop_cnt = 0\n",
    "    for epoch in range(max_epochs):\n",
    "        start_time = time.time()        \n",
    "        model.train()                       # set model to training mode\n",
    "        for _, sample in enumerate(train_dataLoader) :\n",
    "            x, y = sample['image'].to(device), sample['psi'].to(device).float().squeeze(dim=1)\n",
    "            optimizer.zero_grad()           # set gradient to zero\n",
    "            x,y =x.to(device),y.to(device)  # move data to device (cpu/cuda)\n",
    "            predict = model(x)              # forward pass (compute output)\n",
    "            loss = criterion(predict,y)     # forward pass (compute output)\n",
    "            loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                # update model with optimizer\n",
    "            loss_record['train'].append(loss.detach().cpu().item())\n",
    "            # loss_record['train'].append(loss.item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        validation_loss = validation(validation_dataLoader,model,criterion,device)\n",
    "        epoch+=1\n",
    "        loss_record['validation'].extend(validation_loss)\n",
    "        mean_loss = np.mean(validation_loss)\n",
    "        if mean_loss < min_loss:\n",
    "            #save model\n",
    "            min_loss = mean_loss\n",
    "            end_time = time.time()\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f} Cost {:.3f}(secs))'.format(epoch,mean_loss,(end_time - start_time)))\n",
    "            torch.save(model.state_dict(),config['save_path'])\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt+=1\n",
    "            if early_stop_cnt > config['early_stop']:\n",
    "                break\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_loss,loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "def test(test_dataLoader:DataLoader,model:torch.nn.Module,device:torch.device):\n",
    "    model.eval()\n",
    "    predict = []\n",
    "    target = []\n",
    "    for _, sample in enumerate(test_dataLoader) :\n",
    "        x, y = sample['image'].to(device), sample['psi'].to(device).float().squeeze(dim=1)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            predict.append(pred.detach().cpu())\n",
    "            target.append(y.detach().cpu())\n",
    "    predict = torch.cat(predict,dim=0)\n",
    "    target = torch.cat(target,dim=0)\n",
    "    \n",
    "    R2 = r2_score(predict,target)\n",
    "    MSE = mean_squared_error(predict,target)\n",
    "    return R2,MSE,predict,target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanStd(train_fp):\n",
    "    if not os.path.exists(train_fp):\n",
    "        return (0.485, 0.456, 0.406),(0.229, 0.224, 0.225)\n",
    "    # train_fp = \"../01DataPreProcessing/crop_img/\"\n",
    "    RGB_mean = torch.tensor([0,0,0],dtype=torch.float32)\n",
    "    RGB_std = torch.tensor([0,0,0],dtype=torch.float32)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    n = 0\n",
    "    for fp in glob.glob(train_fp+\"*.jpg\"):\n",
    "        with Image.open(fp) as img:\n",
    "            img = transform(img)\n",
    "            RGB_mean += img.mean(dim=(1,2))\n",
    "            RGB_std += img.std(dim=(1,2))\n",
    "            n+=1\n",
    "    RGB_mean /= n\n",
    "    RGB_std /= n\n",
    "    return RGB_mean,RGB_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['validation'])]\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['validation'], c='tab:cyan', label='validation')\n",
    "    plt.ylim(0.0, 1.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_pred(predict,target,lim=2.5):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(target, predict, c='r', alpha=0.5)\n",
    "    plt.plot([-1.5, lim], [-1.5, lim], c='b')\n",
    "    plt.xlim(-1.5, lim)\n",
    "    plt.ylim(-1.5, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self,pre_trained_model:torchvision.models.ResNet):\n",
    "        super(MyResNet,self).__init__()\n",
    "        #3*488*488 -> 24*244*244\n",
    "        #If Conv2d comes with BatchNorm, the bias should be set to False.\n",
    "        self.beforemodel = nn.Sequential(nn.Conv2d(3,24,kernel_size=(3,3),stride=(2,2),padding=(1,1), bias=False)\n",
    "                                         ,nn.BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "                                         ,nn.ReLU())\n",
    "        self.model = pre_trained_model\n",
    "        #(凍結參數,False)\n",
    "        for param in self.model.parameters():\n",
    "            # param.requires_grad = False\n",
    "            param.requires_grad = True\n",
    "        self.model.conv1 = nn.Sequential(nn.Conv2d(24,64,kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False))\n",
    "        self.model.fc = torch.nn.Sequential(torch.nn.Linear(in_features=512,out_features=128),torch.nn.LeakyReLU()\n",
    "                                            ,torch.nn.Linear(in_features=128,out_features=4),torch.nn.LeakyReLU())\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.beforemodel(x)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myResNet = MyResNet(torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT))\n",
    "myResNet = myResNet.to(device)\n",
    "params = params_to_update(myResNet)\n",
    "model = myResNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs('./models/',exist_ok=True)\n",
    "target_only = False\n",
    "\n",
    "config ={\n",
    "    'imput_filepath':'../01DataPreProcessing/aug_images_centerCrop/',\n",
    "    'input_size':(3,488,488),\n",
    "    'random_seed':98,\n",
    "    'max_epochs':2,\n",
    "    'batch_size':1,\n",
    "    # 'optimizer':'SGD',\n",
    "    # 'optim_hparas':{\n",
    "    #     'lr':0.001,\n",
    "    #     'momentum':0.8\n",
    "    # },\n",
    "    'optimizer':'Adam',\n",
    "    'optim_hparas':{\n",
    "        'lr':1e-2,\n",
    "        'betas':(0.9, 0.999),\n",
    "        'eps':1e-8,\n",
    "        'weight_decay':0\n",
    "    },\n",
    "    'lossFunc':'MSELoss',\n",
    "    'loss_hparas':{},\n",
    "    'early_stop':10,\n",
    "    'save_path':'./models/model_with_preCov2d_488_img_aug.pth'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 24, 244, 244]             648\n",
      "       BatchNorm2d-2         [-1, 24, 244, 244]              48\n",
      "              ReLU-3         [-1, 24, 244, 244]               0\n",
      "            Conv2d-4         [-1, 64, 122, 122]          75,264\n",
      "       BatchNorm2d-5         [-1, 64, 122, 122]             128\n",
      "              ReLU-6         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "           Conv2d-11           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 61, 61]             128\n",
      "             ReLU-13           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "           Conv2d-18           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 61, 61]             128\n",
      "             ReLU-20           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-21           [-1, 64, 61, 61]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "             ReLU-24          [-1, 128, 31, 31]               0\n",
      "           Conv2d-25          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-26          [-1, 128, 31, 31]             256\n",
      "           Conv2d-27          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-28          [-1, 128, 31, 31]             256\n",
      "             ReLU-29          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "           Conv2d-34          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 31, 31]             256\n",
      "             ReLU-36          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-37          [-1, 128, 31, 31]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "             ReLU-40          [-1, 256, 16, 16]               0\n",
      "           Conv2d-41          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-42          [-1, 256, 16, 16]             512\n",
      "           Conv2d-43          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-44          [-1, 256, 16, 16]             512\n",
      "             ReLU-45          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "           Conv2d-50          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-51          [-1, 256, 16, 16]             512\n",
      "             ReLU-52          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-53          [-1, 256, 16, 16]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-56            [-1, 512, 8, 8]               0\n",
      "           Conv2d-57            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-58            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-59            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-61            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "           Conv2d-66            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-67            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-68            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-69            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-70            [-1, 512, 1, 1]               0\n",
      "           Linear-71                  [-1, 128]          65,664\n",
      "        LeakyReLU-72                  [-1, 128]               0\n",
      "           Linear-73                    [-1, 4]             516\n",
      "        LeakyReLU-74                    [-1, 4]               0\n",
      "           ResNet-75                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 11,309,244\n",
      "Trainable params: 11,309,244\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.73\n",
      "Forward/backward pass size (MB): 108.78\n",
      "Params size (MB): 43.14\n",
      "Estimated Total Size (MB): 154.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,config['input_size'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Mean&STD for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_mean,RGB_std = getMeanStd(config['imput_filepath'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataLoader,validation_dataLoader,test_dataLoader = BuildDataLoader(\"../01DataPreProcessing/aug_images_centerCrop/*.jpg\",\"../01DataPreProcessing/ftt_psi_10.csv\",config,RGB_mean,RGB_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config['random_seed'])\n",
    "min_loss,loss_record = train(train_dataLoader,validation_dataLoader,model,config,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(loss_record, title='resnet18 fintuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(config['save_path'],map_location=torch.device('cpu')))\n",
    "R2score,mse,predict,target = test(test_dataLoader,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00153331458568573\n",
      "0.13730505108833313\n"
     ]
    }
   ],
   "source": [
    "plot_pred(predict,target)\n",
    "print('R2 Score : %.5f'%R2score.item()) # -infinite ~ 1\n",
    "print('MSE : %.5f'%mse.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "686ae1542fb3ced16f052abbbacf52d5868a6944bbc3d52042eef3f0e78da1db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
